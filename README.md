# Attribution Marketing par ChaÃ®ne de Markov

Ce projet implÃ©mente un pipeline complet dâ€™analyse dâ€™attribution marketing basÃ© sur une **chaÃ®ne de Markov absorbante**. Lâ€™objectif est de dÃ©terminer lâ€™influence de diffÃ©rents points de contact (expositions TV, programmatique, etc.) sur la probabilitÃ© de conversion (achat), en calculant notamment les **effets de suppression** de chaque canal pour attribuer le nombre de conversions Ã  chaque point de contact.

---

## Table des matiÃ¨res

1. [PrÃ©requis](#prÃ©requis)
2. [Arborescence du projet](#arborescence-du-projet)
3. [Installation](#installation)
4. [Description des modules](#description-des-modules)
5. [PrÃ©paration des donnÃ©es](#prÃ©paration-des-donnÃ©es)
6. [ExÃ©cution du pipeline](#exÃ©cution-du-pipeline)
7. [RÃ©sultats gÃ©nÃ©rÃ©s](#rÃ©sultats-gÃ©nÃ©rÃ©s)
8. [Personnalisation / Extensions](#personnalisation--extensions)
9. [FAQ & DÃ©pannage](#faq--dÃ©pannage)

---

## 1. PrÃ©requis

* **SystÃ¨me dâ€™exploitation** : macOS (ou Linux) â€” le tri du CSV utilise la commande `sort` native.
* **Python 3.8+**
* **Environnement virtuel Python** (`venv`)
* **AccÃ¨s en lecture** aux fichiers CSV dâ€™entrÃ©e (Retailer, TV, Programmatique, Mapping, SociodÃ©mographie).
* **Espace disque** suffisant pour stocker les fichiers intermÃ©diaires (CSV consolidÃ©s, triÃ©s, matrices) et les rÃ©sultats.

---

## 2. Arborescence du projet

```plaintext
marketing_attribution_markov/
â”œâ”€â”€ .venv/                          # Environnement virtuel Python
â”œâ”€â”€ data/                           # Dossier des donnÃ©es brutes CSV
â”‚   â”œâ”€â”€ retailer.csv                # Transactions/Achats (Retailer)
â”‚   â”œâ”€â”€ exposures_tv.csv            # Expositions TV
â”‚   â”œâ”€â”€ exposures_programmatique.csv# Expositions Programmatique
â”‚   â”œâ”€â”€ id_mapping.csv              # Mapping device_id / dsp_id â†’ customer_id
â”‚   â””â”€â”€ demographics.csv            # DonnÃ©es socio-dÃ©mographiques (optionnel)
â”œâ”€â”€ data/processed/                 # Dossier pour les fichiers intermÃ©diaires
â”‚   â”œâ”€â”€ merged_data.csv             # Fichier consolidÃ© non triÃ© (gÃ©nÃ©rÃ© automatiquement)
â”‚   â””â”€â”€ merged_sorted.csv           # Fichier consolidÃ© triÃ© (gÃ©nÃ©rÃ© automatiquement)
â”œâ”€â”€ results/                        # Dossier de sortie des rÃ©sultats
â”‚   â”œâ”€â”€ matrices/                   # Matrices (transition, attribution)
â”‚   â”œâ”€â”€ figures/                    # Graphiques gÃ©nÃ©rÃ©s (heatmaps, bar charts)
â”‚   â””â”€â”€ logs/                       # Fichier de logs du pipeline (`pipeline.log`)
â”œâ”€â”€ src/                            # Code source Python
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                   # Configuration des chemins et paramÃ¨tres
â”‚   â”œâ”€â”€ data_loading.py             # Chargement (pandas) des CSV minimal (mapping, Retailer)
â”‚   â”œâ”€â”€ preprocessing.py            # PrÃ©traitement â€œen streamingâ€ (lecture CSV pure)
â”‚   â”œâ”€â”€ transition_counter.py       # Comptage des transitions ligne Ã  ligne
â”‚   â”œâ”€â”€ markov_model.py             # Calcul de la matrice de transition & taux de conversion
â”‚   â”œâ”€â”€ attribution.py              # Effets de suppression et calcul des conversions attribuÃ©es
â”‚   â””â”€â”€ visualization.py            # Fonctions de gÃ©nÃ©ration des graphiques (matplotlib/seaborn)
â”œâ”€â”€ main.py                         # Script principal pour lancer le pipeline complet
â”œâ”€â”€ requirements.txt                # Liste des dÃ©pendances Python
â””â”€â”€ README.md                       # Documentation du projet (ce fichier)
```

---

## 3. Installation

1. **Cloner le dÃ©pÃ´t**

   ```bash
   git clone https://github.com/votre-compte/marketing_attribution_markov.git
   cd marketing_attribution_markov
   ```

2. **CrÃ©ation et activation dâ€™un environnement virtuel**

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate   # macOS / Linux
   # Sous Windows : .venv\Scripts\activate
   ```

3. **Installation des dÃ©pendances**

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

   Le fichier `requirements.txt` contient au minimum :

   ```
   pandas>=1.2
   numpy>=1.19
   matplotlib>=3.3
   seaborn>=0.11
   ```

4. **CrÃ©ation des dossiers de sortie**

   Assurez-vous que les dossiers suivants existent (sinon, crÃ©ezâ€les) :

   ```bash
   mkdir -p data/processed
   mkdir -p results/matrices
   mkdir -p results/figures
   mkdir -p results/logs
   ```

   * `data/processed/` servira Ã  recevoir les fichiers CSV gÃ©nÃ©rÃ©s par le prÃ©traitement.
   * `results/matrices/` contiendra la matrice de transition et le tableau dâ€™attribution final.
   * `results/figures/` contiendra les heatmaps et graphiques dâ€™attribution.
   * `results/logs/` contiendra le fichier `pipeline.log` avec les traces dâ€™exÃ©cution.

---

## 4. Description des modules

### 4.1 `src/config.py`

* DÃ©finit les chemins absolus vers les fichiers de donnÃ©es et de rÃ©sultats (Ã  base de `pathlib.Path`).
* ParamÃ¨tres globaux (par ex. `MARKOV_ORDER` pour indiquer lâ€™ordre de la chaÃ®ne de Markov, ici toujours 1).

**Exemples de variables exposÃ©es** :

```python
ROOT_DIR         # RÃ©pertoire racine du projet
DATA_DIR         # RÃ©pertoire â€œdata/â€
CSV_RETAILER     # data/retailer.csv
CSV_EXPOS_TV     # data/exposures_tv.csv
CSV_EXPOS_PRG    # data/exposures_programmatique.csv
CSV_ID_MAPPING   # data/id_mapping.csv
CSV_DEMOGRAPHICS # data/demographics.csv
RESULTS_DIR      # RÃ©pertoire â€œresults/â€
MATRICES_DIR     # results/matrices/
FIGURES_DIR      # results/figures/
LOGS_DIR         # results/logs/
```

---

### 4.2 `src/data_loading.py`

* Charge, au besoin, les fichiers CSV â€œpetitsâ€ directement en DataFrame pandas.
* Sert Ã  recharger le fichier `retailer.csv` pour compter le nombre total de clients convertis.

Fonctions principales :

* `load_retailer_events()` â†’ DataFrame de `data/retailer.csv`.
* `load_id_mapping()` â†’ DataFrame de `data/id_mapping.csv`.
* `load_demographics()` â†’ DataFrame de `data/demographics.csv` (optionnel).

Note : Le prÃ©traitement â€œlourdâ€ (TV, Programmatique, Retailer) sâ€™effectue dÃ©sormais sans pandas dans `preprocessing.py` pour Ã©conomiser la RAM.

---

### 4.3 `src/preprocessing.py`

* **Lecture â€œpure CSVâ€** (module `csv` de la stdlib) pour minimiser lâ€™empreinte mÃ©moire.

* Charge dâ€™abord `id_mapping.csv` en deux dictionnaires (mapping `device_id`â†’`customer_id`, `dsp_id`â†’`customer_id`), qui tiennent en RAM car relativement petits.

* Parcourt ensuite ligne par ligne :

  1. **`data/exposures_tv.csv`** : si `device_id` est mappÃ©, Ã©crit (`customer_id`, `timestamp_utc`, `TV`, `TV`) dans `data/processed/merged_data.csv`.
  2. **`data/exposures_programmatique.csv`** : si `dsp_id` est mappÃ©, construit `state = "Prog_<campaign_name>"`, `channel = "Programmatique"`, Ã©crit (`customer_id`, `timestamp_utc`, `state`, `channel`) dans le mÃªme `merged_data.csv`.
  3. **`data/retailer.csv`** : Ã©crit chaque ligne comme (`customer_id`, `timestamp_utc`, `Conversion`, `Retailer`) dans `merged_data.csv`.

* **Sortie** :

  * `data/processed/merged_data.csv` (colonnes : `customer_id,timestamp,state,channel`) â€” non triÃ©.
  * Nâ€™accumule jamais plus quâ€™une ligne de CSV et les deux dictionnaires de mapping en mÃ©moire.

**Fonction exposÃ©e** :

```python
def preprocess_data_in_chunks():
    """
    Retourne le chemin du fichier consolidÃ© non triÃ© (merged_data.csv).
    """
```

---

### 4.4 `src/transition_counter.py`

* Parcourt en **streaming** le fichier *triÃ©* `data/processed/merged_sorted.csv`.

* Pour chaque ligne (chaque interaction dâ€™un client), il reconstruit â€œÃ  la volÃ©eâ€ le dernier Ã©tat du client pour comptabiliser les transitions.

  * Si le `customer_id` change, on clÃ´ture lâ€™ancien parcours par une transition `(dernier Ã©tat, No_Conversion)` sâ€™il nâ€™Ã©tait pas dÃ©jÃ  â€œConversionâ€.
  * Pour chaque nouvel Ã©vÃ©nement : incrÃ©mente `transition_counts[(Ã©tat_prÃ©cÃ©dent, Ã©tat_courant)]`.
  * Si lâ€™Ã©vÃ©nement est `Conversion` : ajoute aussi `(Conversion, Conversion)` pour faire de â€œConversionâ€ un Ã©tat absorbant, puis redÃ©marre le parcours au mÃªme client avec `prev_state = 'Start'`.

* **Sortie** :

  * `transition_counts` : dictionnaire `dict[(src_state, dst_state) â†’ count]`
  * `states_set` : ensemble de tous les Ã©tats observÃ©s, incluant `{'Start', 'Conversion', 'No_Conversion', 'TV', 'Prog_<...>'}`

* **Fonction exposÃ©e** :

```python
def compute_transition_counts_from_file(sorted_csv_path):
    """
    Lit merged_sorted.csv triÃ© (customer_id, timestamp) et renvoie (transition_counts, states_set).
    """
```

* **Fonction utilitaire** :

```python
def build_transition_matrix(transition_counts, states_set):
    """
    Construit un DataFrame pandas de la matrice de transition (proba) Ã  partir des counts.
    """
```

---

### 4.5 `src/markov_model.py`

* Ã€ partir de la **matrice de transition** (DataFrame, taille NÃ—N), extrait :

  * Les Ã©tats non absorbants (c.-Ã -d. ceux â‰  `Conversion` et â‰  `No_Conversion`).
  * Les sousâ€matrices `Q` (non absorbants â†’ non absorbants) et `R` (non absorbants â†’ absorbants).

* Calcule la **matrice fondamentale** $N = (I - Q)^{-1}$ et la matrice dâ€™absorption $B = N \times R$.

* Extrait la **probabilitÃ© dâ€™absorption dans â€œConversionâ€ Ã  partir de â€œStartâ€**.

* **Fonction exposÃ©e** :

```python
def compute_conversion_rate(transition_matrix):
    """
    Retourne la probabilitÃ© que, parti de 'Start', on finisse absorbÃ© en 'Conversion'.
    """
```

---

### 4.6 `src/attribution.py`

* **Effet de suppression** (*Removal Effect*) :
  Pour chaque canal (Ã©tat non absorbant, â‰  `Start`, `Conversion`, `No_Conversion`), on :

  1. Supprime la ligne et la colonne correspondantes dans la matrice de transition (Ã©tat retirÃ©).
  2. Recalcule `new_conv_rate = compute_conversion_rate(matrice_sans_ce_canal)`.
  3. Lâ€™**effet** = `base_conv_rate - new_conv_rate`.

* **Attribution finale** :

  * Calcule la somme des effets de suppression (S).
  * Pour chaque Ã©tat :

    ```
    proportion_canal = effet_canal / S  
    conversions_attribuÃ©es = proportion_canal * total_conversions_rÃ©elles
    ```

    oÃ¹ `total_conversions_rÃ©elles` = nombre unique de `customer_id` ayant au moins une conversion dans `retailer.csv`.

* **Fonctions exposÃ©es** :

```python
def compute_all_removal_effects(transition_matrix, base_conv_rate):
    """
    Retourne un dict {etat: effet_de_suppression}.
    """

def compute_channel_attribution(removal_effects, total_conversions):
    """
    Retourne un DataFrame indexÃ© par canal avec colonnes
    ['removal_effect', 'proportion', 'conversions_attribuees'].
    """
```

---

### 4.7 `src/visualization.py`

* GÃ©nÃ¨re les graphiques de sortie (matrice de transition + attribution) au format PNG :

  * **Heatmap** de la matrice de transition (fonction `plot_transition_matrix(...)`).
  * **Bar chart** des conversions attribuÃ©es par canal (fonction `plot_channel_attribution(...)`).

* Ces fonctions utilisent `matplotlib` et `seaborn`.

* Les images sont enregistrÃ©es sous `results/figures/`.

---

## 5. PrÃ©paration des donnÃ©es

Ce pipeline sâ€™appuie sur **cinq** fichiers CSV dâ€™entrÃ©e placÃ©s dans `data/` :

1. **`retailer.csv`**

   * Colonnes attendues :

     ```
     customer_id, timestamp_utc, event_name, brand, product_name, sales, quantity
     ```
   * Correspond aux transactions ou achats dâ€™un client chez le retailer.
   * Exigence minimum : `customer_id` + `timestamp_utc`.

2. **`exposures_tv.csv`**

   * Colonnes attendues :

     ```
     device_id, timestamp_utc, cost_milli_cent
     ```
   * Chaque ligne = une impression TV (par ex. â€œflux publicitaire sâ€™affiche sur la boxâ€).

3. **`exposures_programmatique.csv`**

   * Colonnes attendues :

     ```
     dsp_id, timestamp_utc, campaign_name, device_type, cost_milli_cent
     ```

4. **`id_mapping.csv`**

   * Colonnes attendues :

     ```
     customer_id, device_id, dsp_id
     ```
   * Permet de relier chaque `device_id` (TV) ou `dsp_id` (programmation) Ã  lâ€™`customer_id` du retailer.

5. **`demographics.csv`** (optionnel)

   * Colonnes attendues :

     ```
     customer_id, breed, age, income
     ```
   * DonnÃ©es sociodÃ©mographiques quâ€™on pourrait utiliser ultÃ©rieurement pour segmenter le modÃ¨le.
   * Dans la version courante, on ne lâ€™utilise pas pour le pipeline Markov, mais on peut la charger pour enrichir les donnÃ©es.

---

## 6. ExÃ©cution du pipeline

Une fois lâ€™environnement configurÃ© (cf. Section 3) et les fichiers CSV placÃ©s dans `data/`, lancez :

```bash
(.venv) $ python main.py
```

Le pipeline se dÃ©roule en plusieurs Ã©tapes, tracÃ©es dans le log :

1. **Ã‰tape 1 : PrÃ©traitement â€œen streamingâ€**

   * Appelle `preprocessing.preprocess_data_in_chunks()`.
   * GÃ©nÃ¨re `data/processed/merged_data.csv` (non triÃ©).

2. **Ã‰tape 2 : Tri du CSV consolidÃ©**

   * ExÃ©cute la commande :

     ```bash
     sort -t, -k1,1 -k2,2 data/processed/merged_data.csv \
           -o data/processed/merged_sorted.csv
     ```
   * Produit `data/processed/merged_sorted.csv`, triÃ© par `customer_id` puis `timestamp`.

3. **Ã‰tape 3 : Comptage des transitions**

   * Appelle `transition_counter.compute_transition_counts_from_file('merged_sorted.csv')`.
   * GÃ©nÃ¨re un dictionnaire `transition_counts` et un `states_set`.

4. **Ã‰tape 4 : Construction de la matrice de transition**

   * Appelle `transition_counter.build_transition_matrix(...)`.
   * Enregistre la matrice dans `results/matrices/transition_matrix.csv`.

5. **Ã‰tape 5 : Calcul du taux de conversion global**

   * Appelle `markov_model.compute_conversion_rate(trans_matrix)`.
   * Affiche le taux estimÃ© (`base_conv_rate`).

6. **Ã‰tape 6 : Effets de suppression & attribution**

   * Appelle `attribution.compute_all_removal_effects(trans_matrix, base_conv_rate)`.
   * Recharge `retailer.csv` via `data_loading.load_retailer_events()` pour dÃ©terminer `total_conversions` (nombre unique de `customer_id`).
   * Appelle `attribution.compute_channel_attribution(removal_effects, total_conversions)`.
   * Sauvegarde le rÃ©sultat dans `results/matrices/attribution_by_channel.csv`.

7. **Ã‰tape 7 : Visualisations**

   * GÃ©nÃ¨re et enregistre :

     * `results/figures/transition_matrix_heatmap.png`
     * `results/figures/attribution_bar_chart.png`

8. **Fin**

   * Tous les rÃ©sultats sont disponibles dans le dossier `results/`.
   * Le fichier `results/logs/pipeline.log` contient le dÃ©tail de lâ€™exÃ©cution (horodatages, infos).

---

### 6.1 Analyse dâ€™impact sans canal spÃ©cifique

Le dossier peut contenir des scripts dâ€™analyse manuelle ou complÃ©mentaire, en particulier pour simuler l'impact de la suppression dâ€™un canal spÃ©cifique en dehors du pipeline principal.

Exemples inclus :

- **`analyse1.py`** : affiche le taux de conversion global avec et sans un canal donnÃ© (par exemple, `Prog_Retargeting`) en supprimant dynamiquement la ligne et la colonne correspondantes dans la matrice.
- **`analyse2.py`** : version alternative plus isolÃ©e pour mesurer le taux de conversion simulÃ© en lâ€™absence dâ€™un canal.

Ces scripts se basent directement sur `results/matrices/transition_matrix.csv`.

> ğŸ§  **Note mÃ©thodologique importante** : pour une estimation plus robuste, nous avons exclu les transitions directes de `Start â†’ Conversion`, qui ne reflÃ¨tent pas de vÃ©ritable influence marketing traÃ§able. Cela permet d'Ã©viter dâ€™attribuer artificiellement trop de valeur Ã  une â€œconversion spontanÃ©eâ€.

---

## 7. RÃ©sultats gÃ©nÃ©rÃ©s

Une fois le pipeline terminÃ©, vous trouverez :

1. **`results/matrices/transition_matrix.csv`**

   * CSV de la matrice de transition NÃ—N (N = nombre dâ€™Ã©tats).
   * En-tÃªtes : noms des Ã©tats (start, TV, Prog\_<...>, Conversion, No\_Conversion).

2. **`results/matrices/attribution_by_channel.csv`**

   * CSV listant, pour chaque canal (Ã©tat intermÃ©diaire) :

     ```
     removal_effect, proportion, conversions_attribuees
     ```
   * `removal_effect` = baisse du taux de conversion si on retire le canal.
   * `proportion` = part relative de cet effet parmi tous les canaux.
   * `conversions_attribuees` = nombre de conversions allouÃ©es Ã  ce canal (en pondÃ©rant par le total rÃ©el).

3. **`results/figures/transition_matrix_heatmap.png`**

   * Heatmap visuelle de la matrice de transition (valeurs entre 0 et 1).
   * Permet de voir quelles transitions sont les plus frÃ©quentes (couleurs plus claires).

4. **`results/figures/attribution_bar_chart.png`**

   * Diagramme en barres du nombre de conversions attribuÃ©es par canal.
   * Utile pour prÃ©senter rapidement la rÃ©partition des conversions par point de contact marketing.

5. **`results/logs/pipeline.log`**

   * Trace complÃ¨te (INFO) des Ã©tapes :

     * Horodatages de dÃ©but/fin de chaque Ã©tape.
     * Nombre de lignes lues, nombre dâ€™Ã©tats identifiÃ©s, taux de conversion calculÃ©, etc.
   * Permet de diagnostiquer ou dâ€™auditer le pipeline.

---

## 8. Personnalisation / Extensions

1. **Filtrage temporel**

   * Si vous souhaitez analyser une plage de dates spÃ©cifique, Ã©ditez `src/preprocessing.py` pour ne prendre que les lignes dont `timestamp` est dans lâ€™intervalle souhaitÃ© (ex. entre `2025-01-01` et `2025-03-31`).
   * Vous pouvez aussi supprimer les â€œConversionsâ€ dont la date est antÃ©rieure Ã  toute exposition (pour Ã©viter un biais â€œStartâ†’Conversionâ€).

2. **Segmentation par profil**

   * Chargez `demographics.csv` (client â†’ Ã¢ge, income, etc.).
   * CrÃ©ez des sousâ€ensembles de `merged_sorted.csv` (ex. uniquement les 18-25 ans) et exÃ©cutez le pipeline sÃ©parÃ©ment pour chaque segment.
   * Cela vous donnera une matrice de transition et un calcul dâ€™attribution par segment de population.

3. **Ordre supÃ©rieur de la chaÃ®ne de Markov**

   * Actuellement, on suppose un modÃ¨le *Premier-ordre* (lâ€™Ã©tat suivant dÃ©pend uniquement de lâ€™Ã©tat courant).
   * Si vous souhaitez intÃ©grer lâ€™historique des deux derniers Ã©tats (Markov dâ€™ordre 2), il faudrait :

     * RedÃ©finir la notion â€œdâ€™Ã©tatâ€ comme paire `(Ã©tat_tâˆ’1, Ã©tat_t)` et ajuster le comptage des transitions en consÃ©quence.
     * Adapter `transition_counter` pour gÃ©nÃ©rer ces paires, et `markov_model` pour construire la nouvelle matrice.
   * Attention : le nombre dâ€™Ã©tats croÃ®t rapidement (combinaisons de deux Ã©tats), donc le calcul peut devenir lourd.

4. **Visualisations avancÃ©es**

   * Ajoutez un graphique temporel de lâ€™Ã©volution des probabilitÃ©s de conversion par canal, en dÃ©coupant par fenÃªtre glissante (par exemple, chaque trimestre).
   * GÃ©nÃ©rez un graphique â€œSankeyâ€ reprÃ©sentant les flux de transition les plus frÃ©quents.

5. **Tests unitaires**

   * CrÃ©ez, si nÃ©cessaire, des tests sous `tests/` (avec `pytest`) pour assurer que chaque module fonctionne correctement (ex. que `compute_transition_matrix` renvoie une matrice dont chaque ligne somme Ã  1).

---

## 9. FAQ & DÃ©pannage

### Q1 : Le script est â€œKilledâ€ mÃªme aprÃ¨s la version â€œpure CSVâ€

* **Cause probable** : manque de mÃ©moire vive lors de la phase de tri (`sort`) si le fichier est gigantesque.
* **Solution** :

  * ExÃ©cutez la commande `sort` manuellement en dÃ©coupant le CSV en plus petits morceaux.
  * Par exemple :

    ```bash
    split -l 500000 data/processed/merged_data.csv part_  # dÃ©coupe en fichiers de 500 000 lignes
    sort -t, -k1,1 -k2,2 part_aa -o part_aa_sorted.csv
    sort -t, -k1,1 -k2,2 part_ab -o part_ab_sorted.csv
    # ... rÃ©pÃ©tez pour chaque part_*
    # Puis concatÃ©nez et reâ€tri globalement (approche â€œtri par fusionâ€)
    cat part_*_sorted.csv > merged_sorted_pre.csv
    sort -t, -k1,1 -k2,2 merged_sorted_pre.csv -o data/processed/merged_sorted.csv
    ```
  * Sur macOS, la commande `sort` peut manquer de RAM si le fichier ne tient pas dans `/tmp`. Utilisez lâ€™option `-T` pour spÃ©cifier un dossier temporaire sur un disque plus grand :

    ```bash
    sort -T /Volumes/DisqueExterne/tmp -t, -k1,1 -k2,2 merged_data.csv -o merged_sorted.csv
    ```

### Q2 : Les valeurs â€œStartâ†’Conversionâ€ sont trop Ã©levÃ©es

* **VÃ©rifier le mapping** :

  * Assurez-vous que `id_mapping.csv` couvre la majoritÃ© des devices/dsp.
  * Sinon, de nombreux clients achÃ¨tent sans quâ€™on ait jamais enregistrÃ© dâ€™exposition, dâ€™oÃ¹ le â€œStartâ†’Conversionâ€ massif.
* **Option de filtrage** :

  * Ne conservez dans `merged_data.csv` que les â€œConversionâ€ pour lesquels existe au moins une ligne dâ€™exposition antÃ©rieure pour le mÃªme `customer_id`.
  * Cette rÃ¨gle peut Ãªtre mise avant la phase de tri, en stockant dans un set tous les `customer_id` prÃ©sents dans TV/Programmation, puis en nâ€™Ã©crivant dans â€œConversionâ€ que si le client apparaÃ®t dans ce set.

### Q3 : â€œKeyErrorâ€ ou â€œValueErrorâ€ pendant la construction de la matrice

* **Erreurs possibles** :

  * Si un Ã©tat intermÃ©diaire apparaÃ®t dans `transition_counts` mais pas dans `states_set` (improbable si on ajoute toujours chaque Ã©tat dans `states_set`).
  * Si `transition_matrix` ne contient pas â€œStartâ€ ou â€œConversionâ€ ou â€œNo\_Conversionâ€.
* **Solutions** :

  * VÃ©rifiez que `merged_sorted.csv` contient bien au moins une ligne avec `state='Conversion'`.
  * VÃ©rifiez, avant lâ€™appel Ã  `compute_conversion_rate`, que :

    ```python
    assert 'Start' in trans_matrix.index
    assert 'Conversion' in trans_matrix.index
    assert 'No_Conversion' in trans_matrix.index
    ```
  * Si un de ces Ã©tats manque, inspectez `merged_sorted.csv` pour comprendre pourquoi (p. ex. pas dâ€™Ã©tat â€œNo\_Conversionâ€ car chaque client sâ€™est converti, ou pas dâ€™Ã©tat â€œConversionâ€ du tout).

### Q4 : Les graphiques ne sâ€™enregistrent pas

* VÃ©rifiez que le dossier `results/figures` existe et a les droits dâ€™Ã©criture.
* ContrÃ´lez que la variable `FIGURES_DIR` pointe bien vers `results/figures`.
* Si `seaborn` ou `matplotlib` posent problÃ¨me, essayez de tracer en interactive (`plt.show()`) pour diagnostiquer.

### Q5 : Comment ajouter un nouveau canal (par ex. â€œEmailâ€) ?

1. Dans le prÃ©traitement (Â« streaming Â»), dÃ©tectez les lignes correspondantes Ã  â€œEmailâ€ (selon un nouveau CSV ou si â€œexposures\_programmatique.csvâ€ contient un â€œcampaign\_name=Emailâ€).
2. Ajoutez `state='Email'` et `channel='Email'` pour ces lignes.
3. Relancez le pipeline : le nouvel Ã©tat â€œEmailâ€ apparaÃ®tra dans `states_set` et la matrice de transition intÃ©grera automatiquement ses transitions.

---

> **Note finale**
> Ce pipeline est conÃ§u pour Ãªtre **lÃ©ger en mÃ©moire** et **Ã©mÃ©rite** (il produit un Ã©tat de la chaÃ®ne de Markov complet Ã  chaque exÃ©cution). Pour des volumes de donnÃ©es extrÃªmement importants, la clÃ© est dâ€™ajuster la mÃ©thode de tri (`sort`) ou de passer Ã  une solution distribuÃ©e (Hadoop/Spark) pour le prÃ©traitement. Cependant, pour la plupart des cas de taille â€œmoyenneâ€ (quelques dizaines de millions de lignes), cette approche en pur streaming et tri Unix sâ€™avÃ¨re robuste et reproductible.

Bonne exploitation des rÃ©sultats dâ€™attribution !

Made by â¤ï¸ for Zohra